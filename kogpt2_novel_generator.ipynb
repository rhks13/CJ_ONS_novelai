{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcd07e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\cj\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cj\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\cj\\anaconda3\\lib\\site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\cj\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: requests in c:\\users\\cj\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from packaging->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\cj\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\cj\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\cj\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\cj\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724ed621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
      "     -------------------------------------- 462.8/462.8 kB 7.3 MB/s eta 0:00:00\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "     -------------------------------------- 132.9/132.9 kB 8.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from datasets) (1.21.5)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-11.0.0-cp39-cp39-win_amd64.whl (20.6 MB)\n",
      "     ---------------------------------------- 20.6/20.6 MB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from datasets) (0.12.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\cj\\anaconda3\\lib\\site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\cj\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from datasets) (2022.7.1)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: dill<0.3.7 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cj\\anaconda3\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\cj\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\cj\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Collecting dill<0.3.7\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ---------------------------------------- 110.5/110.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cj\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow, dill, responses, multiprocess, datasets\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.4\n",
      "    Uninstalling dill-0.3.4:\n",
      "      Successfully uninstalled dill-0.3.4\n",
      "Successfully installed datasets-2.9.0 dill-0.3.6 multiprocess-0.70.14 pyarrow-11.0.0 responses-0.18.0 xxhash-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6aa521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import logging\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric, ClassLabel, Sequence\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac06889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad7fff358334279924c7785b91ad4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5657d2b1c0ef4ab1b8ce9c2dd6d976b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['â–ì•ˆë…•',\n",
       " 'í•˜',\n",
       " 'ì„¸',\n",
       " 'ìš”.',\n",
       " 'â–í•œêµ­ì–´',\n",
       " 'â–G',\n",
       " 'P',\n",
       " 'T',\n",
       " '-2',\n",
       " 'â–ì…',\n",
       " 'ë‹ˆë‹¤.',\n",
       " 'ğŸ˜¤',\n",
       " ':)',\n",
       " 'l^o']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "bos_token='</s>', eos_token='</s>', unk_token='<unk>',pad_token='<pad>', mask_token='<mask>')\n",
    "tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d5e9ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25af761eb23b4c229944ffa2d0212787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§€ì¹œ ëª¸ì„ ì´ëŒê³  ê·¸ëŠ” ë‹¤ì‹œ í•œ ë²ˆ ìì‹ ì˜ ê¸¸ì„ ê±¸ì—ˆë‹¤.\n",
      "ê·¸ê°€ ë– ë‚œ ê³³ì€ ë°”ë¡œ ê·¸ ìœ ëª…í•œ 'íŒŒë€ë§Œì¥'ì´ì—ˆë‹¤.\n",
      "ê·¸ëŠ” ì´ì œ ë§‰ ê±¸ìŒë§ˆë¥¼ ì‹œì‘í•œ ê·¸ì˜ ë°œê±¸ìŒì„ ë”°ë¼ê°”ë‹¤.\n",
      "ê·¸ì˜ ë°œìêµ­ ì†Œë¦¬ê°€ ë“¤ë¦¬ëŠ” ìˆœê°„, ê·¸ê°€ ê±¸ì–´ê°€ëŠ” ëª¨ìŠµì´ ë³´ì˜€ë‹¤.\n",
      "\"ì´ì œ ê³§ ë„ì°©í•  ê±°ì•¼.\"\n",
      "ì•„ì§ê¹Œì§€ ê·¸ë¥¼ ê¸°ë‹¤ë¦¬ê³  ìˆë˜ ì‚¬ëŒì€ ì•„ë¬´ë„ ì—†ì—ˆë‹¤.\n",
      "í•˜ì§€ë§Œ ê·¸ë…€ëŠ” ì´ë¯¸ ê·¸ì—ê²Œ ë‹¤ê°€ì˜¨ ì‚¬ëŒì²˜ëŸ¼ ì²œì²œíˆ ê±·ê¸° ì‹œì‘í–ˆë‹¤.\n",
      "ê·¸ë¦¬ê³ ëŠ” ì´ë‚´ ê·¸ë…€ì˜ ë’¤ë¥¼ ë”°ëë‹¤.\n",
      "ê·¸ëŸ¬ì ê·¸ë…€ê°€ ë©ˆì¶° ì„°ë‹¤.\n",
      "ì ì‹œ í›„ ì•„ê¹Œì˜ ì¼ì´ ìƒê°ë‚¬ë‹¤.\n",
      "ë°”ë¡œ ê·¸ë•Œì˜€ë‹¤.\n",
      "ì–´ëŠìƒˆ ê·¸ë…€ë„ ê·¸ë…€ë¥¼ í–¥í•´ ë‹¬ë ¤ê°€ê³  ìˆì—ˆë‹¤.\n",
      "ê·¸ëŸ¬ë‚˜ ê·¸ê²ƒì€ ì ì‹œë¿ì´ì—ˆë‹¤.\n",
      "ë‹¤ì‹œ í•œë²ˆ ê·¸ë…€ì—ê²Œ ë‹¤ê°€ê°€ë ¤ëŠ” ë“¯í–ˆë‹¤.\n",
      "ë§ˆì¹˜ ìì‹ ì´ ì§€ê¸ˆ ì´ ìë¦¬ì— ì„œ ìˆëŠ” ê²ƒ ê°™ì€ ê¸°ë¶„ì´ ë“¤ì—ˆë‹¤.\n",
      "ê°‘ìê¸° ë‚˜íƒ€ë‚œ ê²ƒì€ ë‹¤ë¦„ ì•„ë‹Œ 'ì•„ë¬´ê²ƒë„ ì•„ë‹ˆë‹¤!'\n",
      "ìˆœê°„ì ìœ¼ë¡œ ëŠê»´ì§€ëŠ” ë‘ë ¤ì›€. ê·¸ë¦¬ê³  ê·¸ê²ƒì´ ìì‹ ì„ í–¥í•œ ë¶„ë…¸ë¡œ ëŠê»´ì¡Œë‹¤.\n",
      "ìì‹ ì˜ í–‰ë™ì´ ìì‹ ì—ê²Œ ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ì§€ ì•Œ ìˆ˜ ì—†ëŠ” ì¼ì´ì—ˆë‹¤.\n",
      "ìì‹ ì´ ì™œ ì´ë ‡ê²Œ ë˜ì—ˆëŠ”ì§€.\n",
      "ì§€ê¸ˆê» ì•Œê³  ìˆì—ˆë˜ ê²ƒì„ ëª¨ë‘ ìŠê³  ê·¸ì € ë©í•˜ë‹ˆ ì•‰ì•„ ìˆì„ ë¿ì´ì—ˆë‹¤.\n",
      "í•œì°¸ì„ ê·¸ë ‡ê²Œ ê¸°ë‹¤ë¦° í›„ì—ì•¼ ë¹„ë¡œì†Œ ê¹¨ë‹¬ì•˜ë‹¤.\n",
      "ë§ˆì§€ë§‰ìœ¼ë¡œ ë‚¨ì€ ì‹œê°„ì€ ë‹¨ í•˜ë£¨ë¿ì¸ ê²ƒì´ë‹¤.\n",
      "ê·¸ë˜ì„œì¸ì§€ ì˜¤ëŠ˜ì€ ë” ì´ìƒ ì•„ë¬´ê²ƒë„ í•  ìˆ˜ê°€ ì—†ë‹¤.\n",
      "ë” ì´ìƒì€ ì•„ë¬´ ê²ƒë„ í•˜ì§€ ì•Šê¸°ë¡œ í–ˆë‹¤.\n",
      "ëŒ€ì‹  ì¡°ê¸ˆì´ë¼ë„ ë¹¨ë¦¬ ì¼ì–´ë‚˜ë ¤ê³  ë…¸ë ¥í–ˆë‹¤.\n",
      "ë¬¼ë¡  ì•„ì§ê¹Œì§€ëŠ” ì•„ë¬´ëŸ° í–‰ë™ ì—†ì´ ê·¸ëƒ¥ ì§€ë‚˜ì¹  ìˆ˜ë°–ì— ì—†ì—ˆì§€ë§Œ, ê·¸ë˜ë„ ì—¬ì „íˆ ë¬´ì–¸ê°€ë¥¼ í•˜ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì´ ë“¤ì–´ ë”ìš± ì—´ì‹¬íˆ ì›€ì§ì´ê³  ìˆë‹¤.\n",
      "ì˜¤ëŠ˜ë”°ë¼ ìœ ë‚œíˆ ì¶”ì› ë˜ ë‚ ì”¨ì— ì˜¨ëª¸ì—ì„œ ë•€ë°©ìš¸ë“¤ì´ í˜ëŸ¬ë‚´ë¦¬ê³  ìˆì—ˆê³ , ì–´ëŠë§ ì°¨ê°€ìš´ ë°”ëŒì´ ë¶ˆì–´ì™€ ë§ˆì¹˜ ì–¼ìŒ ìœ„ë¥¼ ê±·ëŠ” ë“¯í•œ ì°©ê°ì´ ì¼ê¸°ë„ í–ˆì§€ë§Œ, ê·¸ëŸ° ìƒê°ì€ ì „í˜€ ë“¤ì§€ ì•Šì•˜ë‹¤.\n",
      "ì˜¤íˆë ¤ ì˜¤íˆë ¤ ë§ˆìŒì´ í¸í•´ì¡Œë‹¤.\n",
      "ë­”ê°€ì— ì—´ì¤‘í•˜ê³  ìˆë‹¤ëŠ” ëŠë‚Œì´ ë“¤ì–´ì„œë‹¤.\n",
      "í˜¹ì‹œë¼ë„ ëˆ„êµ°ê°€ì˜ ë„ì›€ì„ ë°›ì„ ìˆ˜ë„ ìˆì§€ ì•Šì„ê¹Œ í•˜ëŠ” ìƒê°ì— ê°€ìŠ´ì´ ë‘ê·¼ê±°ë ¸ë‹¤.\n",
      "ì‚¬ì‹¤ ë‚˜ëŠ” ë‚´ì¼ì´ë©´ ë˜ ë‹¤ë¥¸ ì‚¬ëŒì´ ë‚˜íƒ€ë‚ ì§€ë„ ëª¨ë¥¸ë‹¤ëŠ” ìƒê°ì„ í•´ë³¸ ì ì´ ê±°ì˜ ì—†ì—ˆê¸° ë•Œë¬¸ì´ë‹¤.\n",
      "ë‚˜ëŠ” ì •ë§ì´ì§€ ë‚´ê°€ ë¬´ìŠ¨ ì¼ì„ í•´ì•¼ í• ì§€ ëª°ëë‹¤.\n",
      "ë‚´ê°€ ë¬´ì—‡ì„ í•˜ë“  ìƒê´€ì—†ì§€ë§Œ ë§ì´ë‹¤.\n",
      "ë‚´ì¼ì€ ê¼­ ë‚˜ í˜¼ìë§Œì˜ ì‹œê°„ì´ ë  í…Œë‹ˆê¹Œ.\n",
      "ë‚˜ ì—­ì‹œ ë§ˆì°¬ê°€ì§€ì´ë‹¤.\n",
      "ë‹¹ì—°íˆ ë‚˜ë„ ë‹¹ë¶„ê°„ì€ ì´ëŸ° ì‹ìœ¼ë¡œ ì§€ë‚´ì•¼ë§Œ í•œë‹¤.\n",
      "ì™œëƒí•˜ë©´ ë‚œ ì–¸ì œë‚˜ ë‚˜ë¥¼ ìœ„í•´ ëª¨ë“  ê²ƒë“¤ì„ í¬ìƒí•´ì•¼ í•˜ê¸° ë•Œë¬¸ì´ê¸°ë„ í•˜ë‹¤.\n",
      "ë‚œ í•­ìƒ ë‚˜ì˜ ê³ì— ìˆì–´ì£¼ê³  ìˆê¸° ë•Œë¬¸ì—\n",
      "ë‚˜ì˜ ì¡´ì¬ëŠ” ë‚˜ì—ê²Œ ìˆì–´ì„œ ê°€ì¥ ì†Œì¤‘í•œ ì¡´ì¬ì´ê¸° ë•Œë¬¸ì´ë‹¤. ë§Œì•½ ê·¸ë ‡ë‹¤ë©´ ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œ?\n",
      "ìš°ì„  ë¨¼ì € ë‚´ê²Œ í•„ìš”í•œ ê²ƒì´ ë¬´ì—‡ì¸ì§€ë¶€í„° ìƒê°í•´ë³´ì.\n",
      "ë¨¼ì € ë‹¹ì‹ ì˜ ì¡´ì¬ë¥¼ ì•Œì•„ë³´ëŠ” ì¼ì´ë‹¤.\n",
      "ë˜í•œ, ìš°ë¦¬ê°€ í•¨ê»˜ ì‚´ì•„ê°€ë©´ì„œ ê²ªê²Œ ë˜ëŠ” ì—¬ëŸ¬ ê°€ì§€ ì¼ë“¤ì„ ë– ì˜¬ë ¤ë³¼ í•„ìš”ê°€ ìˆê² ê³ , ë˜í•œ ìš°ë¦¬ì˜ ê´€ê³„ë¥¼ ëŒì•„ë³´ê³  ìƒˆë¡œìš´ ê´€ê³„ë“¤ì„ ë§Œë“¤ì–´ë‚˜ê°€ëŠ” ë° ë„ì›€ì´ ë˜ë¦¬ë¼ ìƒê°í•œë‹¤.\n",
      "ë‘˜ì§¸, ìš°ë¦¬ë¥¼ ë‘˜ëŸ¬ì‹¼ í™˜ê²½ì„ ì‚´í´ë³´ì•„ì•¼ê² ë‹¤. ë§Œì¼ ì´ëŸ¬í•œ í™˜ê²½ ì†ì—ì„œ ì‚´ì•„ê°€ëŠ” ì‚¬ëŒë“¤ì´ ìˆë‹¤ë©´ ìš°ë¦¬ëŠ” ì„œë¡œì—ê²Œ ë§ì€ ìƒì²˜ë¥¼ ì¤„ ê²ƒì´ê¸° ë•Œë¬¸ì—, ê·¸ë“¤ì„\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "text = 'ì§€ì¹œ ëª¸ì„ ì´ëŒê³  ê·¸ëŠ”'\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "gen_ids = model.generate(input_ids,\n",
    "                           max_length=512,\n",
    "                           repetition_penalty=2.0,\n",
    "                           pad_token_id=tokenizer.pad_token_id,\n",
    "                           eos_token_id=tokenizer.eos_token_id,\n",
    "                           bos_token_id=tokenizer.bos_token_id,\n",
    "                           use_cache=True)\n",
    "generated = tokenizer.decode(gen_ids[0])\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf5a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('romance.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e844595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def labeling(string):\n",
    "    return \" \".join(string.split('.')[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9208664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['labels'] = df['context'].map(labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "649e3626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â€œë„ëŒ€ì²´ ë¬´ìŠ¨ ìˆ ìˆ˜ë¥¼ ë¶€ë¦° ê±°ì•¼.â€\\nìŠ¹ì „ ì—°íšŒì˜ ë§ˆì§€ë§‰ ë‚ ì´ì—ˆë‹¤. ë‚ ì¹´ë¡œìš´ ë§ì´ ...</td>\n",
       "      <td>â€œë„ëŒ€ì²´ ë¬´ìŠ¨ ìˆ ìˆ˜ë¥¼ ë¶€ë¦° ê±°ì•¼ â€\\nìŠ¹ì „ ì—°íšŒì˜ ë§ˆì§€ë§‰ ë‚ ì´ì—ˆë‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë§ˆì°¨ê°€ ë„ì°©í•œ ê³³ì€ ì•„ë¦„ë‹µê³  ì›…ì¥í•œ ì €íƒì´ì—ˆë‹¤.\\n\\nì˜¬ë¦¬ë¹„ì•„ëŠ” ì €íƒì„ ì˜¬ë ¤ë‹¤ë³´ì•˜ë‹¤...</td>\n",
       "      <td>ë§ˆì°¨ê°€ ë„ì°©í•œ ê³³ì€ ì•„ë¦„ë‹µê³  ì›…ì¥í•œ ì €íƒì´ì—ˆë‹¤ \\n\\nì˜¬ë¦¬ë¹„ì•„ëŠ” ì €íƒì„ ì˜¬ë ¤ë‹¤ë³´ì•˜ë‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ëª¨ë“  ê²Œ ë‹¬ë¼ì¡Œë‹¤.\\n\\nìœ ëª¨ëŠ” ëŒì•„ì˜¤ì§€ ì•Šì•˜ê³  ëŠ˜ ë¹µê³¼ ê³ ê¸°, ì‹ ì„ í•œ ì±„ì†Œì™€ ê³¼ì¼...</td>\n",
       "      <td>ëª¨ë“  ê²Œ ë‹¬ë¼ì¡Œë‹¤ \\n\\nìœ ëª¨ëŠ” ëŒì•„ì˜¤ì§€ ì•Šì•˜ê³  ëŠ˜ ë¹µê³¼ ê³ ê¸°, ì‹ ì„ í•œ ì±„ì†Œì™€ ê³¼ì¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì˜¤ëŠ˜ë„ ì•ˆ ì˜¤ì‹œë ¤ë‚˜.\\n\\nì˜¬ë¦¬ë¹„ì•„ëŠ” í•œìˆ¨ì„ ì‚¼ì¼°ë‹¤. ì°¨ëŠ” ì‹ì€ ì§€ ì˜¤ë˜ì˜€ë‹¤. ë²Œì¨...</td>\n",
       "      <td>ì˜¤ëŠ˜ë„ ì•ˆ ì˜¤ì‹œë ¤ë‚˜ \\n\\nì˜¬ë¦¬ë¹„ì•„ëŠ” í•œìˆ¨ì„ ì‚¼ì¼°ë‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>â€œê·¸ëŸ¬ë©´ ë‹¤ìŒ ì£¼ ì›”ìš”ì¼ì—ë„ íƒœì ì „í•˜ë¥¼ ëµˆëŸ¬ ì˜¤ì‹œëŠ” ê±°ì˜ˆìš”?â€\\në§ˆì°¨ê°€ ê¶ ë°–ìœ¼ë¡œ...</td>\n",
       "      <td>â€œê·¸ëŸ¬ë©´ ë‹¤ìŒ ì£¼ ì›”ìš”ì¼ì—ë„ íƒœì ì „í•˜ë¥¼ ëµˆëŸ¬ ì˜¤ì‹œëŠ” ê±°ì˜ˆìš”?â€\\në§ˆì°¨ê°€ ê¶ ë°–ìœ¼ë¡œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>* * *\\nâ€œê³µâ€¦â€¦ í¡!â€\\në ˆì•„ëŠ” ì €ë„ ëª¨ë¥´ê²Œ ê³µì‘ë‹˜ì´ë¼ê³  ë¶€ë¥¼ ë»”í•œ ì…ì„ ë‘ ...</td>\n",
       "      <td>* * *\\nâ€œê³µâ€¦â€¦ í¡!â€\\në ˆì•„ëŠ” ì €ë„ ëª¨ë¥´ê²Œ ê³µì‘ë‹˜ì´ë¼ê³  ë¶€ë¥¼ ë»”í•œ ì…ì„ ë‘ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>* * *\\n\\n\\n\\ní…Œì˜¤ë¥¼ ë”°ë¼ì˜¨ ë°© ì•ì— ì„  ì•…í‚¤ì•„ê°€ ì•ˆìª½ì„ í›‘ì—ˆë‹¤. ì˜¤ë˜ëœ ...</td>\n",
       "      <td>* * *\\n\\n\\n\\ní…Œì˜¤ë¥¼ ë”°ë¼ì˜¨ ë°© ì•ì— ì„  ì•…í‚¤ì•„ê°€ ì•ˆìª½ì„ í›‘ì—ˆë‹¤  ì˜¤ë˜ëœ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>* * *\\n\\n\\n\\në ˆì•„ ì—­ì‹œ ì ì´ ì˜¤ì§€ ì•Šì•˜ëŠ”ì§€, ìˆ„ì„ ê±¸ì¹œ ì±„ ê·¸ë¥¼ ë°”ë¼ë³´ê³ ...</td>\n",
       "      <td>* * *\\n\\n\\n\\në ˆì•„ ì—­ì‹œ ì ì´ ì˜¤ì§€ ì•Šì•˜ëŠ”ì§€, ìˆ„ì„ ê±¸ì¹œ ì±„ ê·¸ë¥¼ ë°”ë¼ë³´ê³ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>* * *\\n\\n\\n\\ní•˜ì§€ë§Œ ë ˆì•„ì˜ ìƒê°ê³¼ëŠ” ë°˜ëŒ€ë¡œ ì•…í‚¤ì•„ ì—­ì‹œ í½ ë‚œê°í•´í•˜ê³  ìˆ...</td>\n",
       "      <td>* * *\\n\\n\\n\\ní•˜ì§€ë§Œ ë ˆì•„ì˜ ìƒê°ê³¼ëŠ” ë°˜ëŒ€ë¡œ ì•…í‚¤ì•„ ì—­ì‹œ í½ ë‚œê°í•´í•˜ê³  ìˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>* * *\\nâ€œëˆˆ ë– .â€\\në ˆì•„ê°€ ë‘ ëˆˆì„ ëœ¨ì, ê¸ˆë°©ì´ë¼ë„ ì½”ê°€ ë‹¿ì„ ê²ƒì²˜ëŸ¼ ê°€ê¹Œ...</td>\n",
       "      <td>* * *\\nâ€œëˆˆ ë–  â€\\në ˆì•„ê°€ ë‘ ëˆˆì„ ëœ¨ì, ê¸ˆë°©ì´ë¼ë„ ì½”ê°€ ë‹¿ì„ ê²ƒì²˜ëŸ¼ ê°€ê¹Œ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     â€œë„ëŒ€ì²´ ë¬´ìŠ¨ ìˆ ìˆ˜ë¥¼ ë¶€ë¦° ê±°ì•¼.â€\\nìŠ¹ì „ ì—°íšŒì˜ ë§ˆì§€ë§‰ ë‚ ì´ì—ˆë‹¤. ë‚ ì¹´ë¡œìš´ ë§ì´ ...   \n",
       "1     ë§ˆì°¨ê°€ ë„ì°©í•œ ê³³ì€ ì•„ë¦„ë‹µê³  ì›…ì¥í•œ ì €íƒì´ì—ˆë‹¤.\\n\\nì˜¬ë¦¬ë¹„ì•„ëŠ” ì €íƒì„ ì˜¬ë ¤ë‹¤ë³´ì•˜ë‹¤...   \n",
       "2     ëª¨ë“  ê²Œ ë‹¬ë¼ì¡Œë‹¤.\\n\\nìœ ëª¨ëŠ” ëŒì•„ì˜¤ì§€ ì•Šì•˜ê³  ëŠ˜ ë¹µê³¼ ê³ ê¸°, ì‹ ì„ í•œ ì±„ì†Œì™€ ê³¼ì¼...   \n",
       "3     ì˜¤ëŠ˜ë„ ì•ˆ ì˜¤ì‹œë ¤ë‚˜.\\n\\nì˜¬ë¦¬ë¹„ì•„ëŠ” í•œìˆ¨ì„ ì‚¼ì¼°ë‹¤. ì°¨ëŠ” ì‹ì€ ì§€ ì˜¤ë˜ì˜€ë‹¤. ë²Œì¨...   \n",
       "4     â€œê·¸ëŸ¬ë©´ ë‹¤ìŒ ì£¼ ì›”ìš”ì¼ì—ë„ íƒœì ì „í•˜ë¥¼ ëµˆëŸ¬ ì˜¤ì‹œëŠ” ê±°ì˜ˆìš”?â€\\në§ˆì°¨ê°€ ê¶ ë°–ìœ¼ë¡œ...   \n",
       "...                                                 ...   \n",
       "1695  * * *\\nâ€œê³µâ€¦â€¦ í¡!â€\\në ˆì•„ëŠ” ì €ë„ ëª¨ë¥´ê²Œ ê³µì‘ë‹˜ì´ë¼ê³  ë¶€ë¥¼ ë»”í•œ ì…ì„ ë‘ ...   \n",
       "1696  * * *\\n\\n\\n\\ní…Œì˜¤ë¥¼ ë”°ë¼ì˜¨ ë°© ì•ì— ì„  ì•…í‚¤ì•„ê°€ ì•ˆìª½ì„ í›‘ì—ˆë‹¤. ì˜¤ë˜ëœ ...   \n",
       "1697  * * *\\n\\n\\n\\në ˆì•„ ì—­ì‹œ ì ì´ ì˜¤ì§€ ì•Šì•˜ëŠ”ì§€, ìˆ„ì„ ê±¸ì¹œ ì±„ ê·¸ë¥¼ ë°”ë¼ë³´ê³ ...   \n",
       "1698  * * *\\n\\n\\n\\ní•˜ì§€ë§Œ ë ˆì•„ì˜ ìƒê°ê³¼ëŠ” ë°˜ëŒ€ë¡œ ì•…í‚¤ì•„ ì—­ì‹œ í½ ë‚œê°í•´í•˜ê³  ìˆ...   \n",
       "1699  * * *\\nâ€œëˆˆ ë– .â€\\në ˆì•„ê°€ ë‘ ëˆˆì„ ëœ¨ì, ê¸ˆë°©ì´ë¼ë„ ì½”ê°€ ë‹¿ì„ ê²ƒì²˜ëŸ¼ ê°€ê¹Œ...   \n",
       "\n",
       "                                                 labels  \n",
       "0                  â€œë„ëŒ€ì²´ ë¬´ìŠ¨ ìˆ ìˆ˜ë¥¼ ë¶€ë¦° ê±°ì•¼ â€\\nìŠ¹ì „ ì—°íšŒì˜ ë§ˆì§€ë§‰ ë‚ ì´ì—ˆë‹¤  \n",
       "1        ë§ˆì°¨ê°€ ë„ì°©í•œ ê³³ì€ ì•„ë¦„ë‹µê³  ì›…ì¥í•œ ì €íƒì´ì—ˆë‹¤ \\n\\nì˜¬ë¦¬ë¹„ì•„ëŠ” ì €íƒì„ ì˜¬ë ¤ë‹¤ë³´ì•˜ë‹¤  \n",
       "2     ëª¨ë“  ê²Œ ë‹¬ë¼ì¡Œë‹¤ \\n\\nìœ ëª¨ëŠ” ëŒì•„ì˜¤ì§€ ì•Šì•˜ê³  ëŠ˜ ë¹µê³¼ ê³ ê¸°, ì‹ ì„ í•œ ì±„ì†Œì™€ ê³¼ì¼...  \n",
       "3                          ì˜¤ëŠ˜ë„ ì•ˆ ì˜¤ì‹œë ¤ë‚˜ \\n\\nì˜¬ë¦¬ë¹„ì•„ëŠ” í•œìˆ¨ì„ ì‚¼ì¼°ë‹¤  \n",
       "4     â€œê·¸ëŸ¬ë©´ ë‹¤ìŒ ì£¼ ì›”ìš”ì¼ì—ë„ íƒœì ì „í•˜ë¥¼ ëµˆëŸ¬ ì˜¤ì‹œëŠ” ê±°ì˜ˆìš”?â€\\në§ˆì°¨ê°€ ê¶ ë°–ìœ¼ë¡œ...  \n",
       "...                                                 ...  \n",
       "1695  * * *\\nâ€œê³µâ€¦â€¦ í¡!â€\\në ˆì•„ëŠ” ì €ë„ ëª¨ë¥´ê²Œ ê³µì‘ë‹˜ì´ë¼ê³  ë¶€ë¥¼ ë»”í•œ ì…ì„ ë‘ ...  \n",
       "1696  * * *\\n\\n\\n\\ní…Œì˜¤ë¥¼ ë”°ë¼ì˜¨ ë°© ì•ì— ì„  ì•…í‚¤ì•„ê°€ ì•ˆìª½ì„ í›‘ì—ˆë‹¤  ì˜¤ë˜ëœ ...  \n",
       "1697  * * *\\n\\n\\n\\në ˆì•„ ì—­ì‹œ ì ì´ ì˜¤ì§€ ì•Šì•˜ëŠ”ì§€, ìˆ„ì„ ê±¸ì¹œ ì±„ ê·¸ë¥¼ ë°”ë¼ë³´ê³ ...  \n",
       "1698  * * *\\n\\n\\n\\ní•˜ì§€ë§Œ ë ˆì•„ì˜ ìƒê°ê³¼ëŠ” ë°˜ëŒ€ë¡œ ì•…í‚¤ì•„ ì—­ì‹œ í½ ë‚œê°í•´í•˜ê³  ìˆ...  \n",
       "1699  * * *\\nâ€œëˆˆ ë–  â€\\në ˆì•„ê°€ ë‘ ëˆˆì„ ëœ¨ì, ê¸ˆë°©ì´ë¼ë„ ì½”ê°€ ë‹¿ì„ ê²ƒì²˜ëŸ¼ ê°€ê¹Œ...  \n",
       "\n",
       "[1700 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a8385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë”©í•˜ëŠ” ê³¼ì •\n",
    "from datasets import Dataset\n",
    "train_data = Dataset.from_pandas(df[:int(len(df)*0.8)])\n",
    "eval_data = Dataset.from_pandas(df[int(len(df)*0.8):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1002547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51977ced5d564c9a8af41dc7dae0c5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d13e17c6da46fc9209299e7cad54bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"context\"], truncation=True, max_length=512)\n",
    "\n",
    "train_token = train_data.map(tokenize_function, batched=True)\n",
    "eval_token = eval_data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "786d5573",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'mlm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21016\\1977088461.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_collator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmlm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlm_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'mlm'"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer,mlm=True, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870c6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9be24a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39d8a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/config.json from cache at C:\\Users\\CJ/.cache\\huggingface\\transformers\\13bb826cf24517d7849a701e02452715a67c5e560142be3d4735442b2a545809.6b384eec6effdd44287f67715cd55bd0dff2cf846d843b932b43ba7b632b8b1e\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/pytorch_model.bin from cache at C:\\Users\\CJ/.cache\\huggingface\\transformers\\495b405e3742953dbcc56685d1560fa02a2d86fc50b891868990a4471b06c934.4ebf112d34c2c8fc657866680005d92d21859c52c0ef5e941fa640129b2f8f88\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at skt/kogpt2-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea69b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_token,\n",
    "    eval_dataset=eval_token,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74c53d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: context, __index_level_0__.\n",
      "***** Running training *****\n",
      "  Num examples = 1360\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 510\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21016\\4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1282\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m                     \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1285\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1787\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1789\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   1829\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1830\u001b[0m             \u001b[1;31m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1831\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m   1933\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1934\u001b[0m             \u001b[0minner_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1935\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1937\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d77c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e910a800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0702a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
